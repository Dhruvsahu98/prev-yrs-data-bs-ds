Question Number : 181 Question Id : 640653699389 Question Type : MCQ Is Question
Mandatory : No Calculator : None Response Time : N.A Think Time : N.A Minimum Instruction Time : 0
Correct Marks : 2
Question Label : Multiple Choice Question
What happens when a Spark Structured Streaming pipeline operating with Kafka as source is subject to a failure of a machine in either of the Kafka cluster or the Spark cluster?
Options :
6406532335426. ❌ Failure of a machine in the Kafka cluster will result in an Exception in the Spark pipeline which will then fail and halt.
6406532335427. ❌ The Spark pipeline will not be able to start again from previously committed offset by restarting itself, resulting in at least-once processing semantics
6406532335428. ❌ Irrespective of whatever machine fails, Spark will throw an error and halt.
6406532335429. ✅ The pipeline will be restarted automatically by Spark which is able to pick up the exact data from Kafka which was being processed at the time of error, resulting in exactly-once semantics.
6406532335430. ❌ Data that is being processed will not be processed again, resulting in atmost-once semantics.

Question Number : 182 Question Id : 640653699390 Question Type : MCQ Is Question
Mandatory : No Calculator : None Response Time : N.A Think Time : N.A Minimum Instruction Time : 0
Correct Marks : 2
Question Label : Multiple Choice Question
A big data streaming application that uses Kafka as source is observed to be really slow. The Kafka cluster has 2 broker nodes and this application is reading from 1 topic that has 10 partitions. On closer investigation, it was found that Kafka is not scaling to the velocity of input data coming in. What can you first try to do to scale Kafka further while incurring minimal costs?
Options :