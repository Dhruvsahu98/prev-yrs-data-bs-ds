```python
import matplotlib.pyplot as plt
import numpy as np

# Create a grid of points
x = np.linspace(-2, 2, 100)
y = np.linspace(-1, 2, 100)
X, Y = np.meshgrid(x, y)

# Define the function
def f(x, y):
  return x**2 + y**2

# Create a contour plot
CS = plt.contour(X, Y, f(X, Y), 20)

# Add labels to the contour lines
plt.clabel(CS, inline=1, fontsize=8)

# Set the title of the plot
plt.title("Contour Plot")

# Set the labels of the axes
plt.xlabel("x")
plt.ylabel("y")

# Show the plot
plt.show()
```

Options :
6406531887690. ✅ There might be two flat minima
6406531887691. ❌ There might be two flat maxima
6406531887692. ✅ There is one flat maxima
6406531887693. ❌ There is one flat minima

Question Number : 117 Question Id : 640653564739 Question Type : MSQ Is Question
Mandatory : No Calculator : None Response Time : N.A Think Time : N.A Minimum Instruction Time : 0
Correct Marks : 3 Selectable Option : 0

Question Label : Multiple Select Question
Suppose that a model produces zero training error without using any regularization technique. What happens if we use $L_2$ regularization and retrain the model, in general?

Options :
6406531887694. ✅ This might increase training error
6406531887695. ✅ This might decrease test error
6406531887696. 
